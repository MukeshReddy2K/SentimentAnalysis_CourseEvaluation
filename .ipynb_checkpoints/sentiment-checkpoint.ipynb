{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Course Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python Notebook to summarize course evaluations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation of libraries\n",
    "!pip install squarify\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "### Load Questions and Responses from CSV\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries\n",
    "import seaborn as sbn\n",
    "import squarify as sqfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config variables\n",
    "_DATA_FILE_QUESTIONS_ = \"../data/te_questions.csv\"\n",
    "_DATA_FILE_RESPONSES_ = \"../data/te_responses.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load questions\n",
    "df_questions = pd.read_csv(_DATA_FILE_QUESTIONS_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load responses\n",
    "df_responses = pd.read_csv(_DATA_FILE_RESPONSES_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect questions dataframe\n",
    "print(\"\\nQuestions dataframe:\")\n",
    "print(df_questions.info())\n",
    "print(\"-\"*50)\n",
    "# number of rows\n",
    "print(\"Number of questions: \", len(df_questions))\n",
    "print(\"-\"*50)\n",
    "print(df_questions.head())\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions stats\n",
    "print(\"\\nQuestions stats:\")\n",
    "# how many different forms are there (unique FormNumber)\n",
    "print(\"Number of unique forms: \", df_questions['FormNumber'].nunique())\n",
    "# min # of questions for a form\n",
    "print(\"Min # of questions for a form: \", df_questions.groupby('FormNumber').size().min())\n",
    "# max # of questions for a form\n",
    "print(\"Max # of questions for a form: \", df_questions.groupby('FormNumber').size().max())\n",
    "# avg # of questions for a form\n",
    "print(\"Avg # of questions for a form: \", df_questions.groupby('FormNumber').size().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the data to see the distribution of questions per form\n",
    "# label the graph too, and provide x and y axis labels\n",
    "# i want to set size of the images, how do i do that?\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "df_questions.groupby('FormNumber').size().plot(kind='hist', bins=10)\n",
    "plt.title('Distribution of questions per form')\n",
    "plt.xlabel('Number of questions')\n",
    "plt.ylabel('Number of forms')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what other kinds of plots can i make for this data?\n",
    "# how about a bar plot?\n",
    "plt.figure(figsize=(10, 8))\n",
    "df_questions.groupby('FormNumber').size().plot(kind='bar')\n",
    "plt.title('Distribution of questions per form')\n",
    "plt.xlabel('Form number')\n",
    "plt.ylabel('Number of questions')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unique questions count\n",
    "print(\"\\nUnique questions count:\")\n",
    "print(df_questions['Question'].nunique())\n",
    "print(\"-\"*50)\n",
    "\n",
    "# list unique questions\n",
    "# print(\"\\nUnique questions:\")\n",
    "# print(df_questions['Question'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we analyze the reponses dataframe\n",
    "\n",
    "# Inspect responses dataframe\n",
    "print(\"\\nResponses dataframe:\")\n",
    "print(df_responses.info())\n",
    "print(\"-\"*50)\n",
    "# number of rows\n",
    "print(\"Number of responses: \", len(df_responses))\n",
    "print(\"-\"*50)\n",
    "# first 5 rows\n",
    "print(df_responses.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart of responses by Career\n",
    "# There are six Careers : UGRD, GRAD, PHRM, LAW, MED, OPT\n",
    "# we set 6 bold colors\n",
    "colors_career = ['#C8102E', '#00B388', '#640817', '#888B8D', '#FFF9D9', '#F6BE00']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['Career'].value_counts().plot(kind='pie', autopct='%1.1f%%', wedgeprops={'alpha':0.75}, colors=colors_career)\n",
    "plt.ylabel('')\n",
    "plt.title('Responses by Career')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal bar chart of responses by Career\n",
    "# how to use different colors for the bars?\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['Career'].value_counts().plot(kind='barh', color=colors_career)\n",
    "plt.title('Responses by Career')\n",
    "plt.xlabel('Number of responses')\n",
    "plt.ylabel('Career')\n",
    "# show values on bars\n",
    "for index, value in enumerate(df_responses['Career'].value_counts()):\n",
    "    plt.text(value, index, str(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart of responses by InstrModeDescr\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['InstrModeDescr'].value_counts().plot(kind='pie', autopct='%1.1f%%', wedgeprops={'alpha':0.75})\n",
    "plt.ylabel('')  \n",
    "plt.title('Responses by Instruction Mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal bar chart of responses by InstrModeDescr\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['InstrModeDescr'].value_counts().plot(kind='barh')\n",
    "plt.title('Responses by Instruction Mode')\n",
    "plt.xlabel('Number of responses')\n",
    "plt.ylabel('Instruction Mode')\n",
    "# show values on bars\n",
    "for index, value in enumerate(df_responses['InstrModeDescr'].value_counts()):\n",
    "    plt.text(value, index, str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses by component (lecture/lab etc)\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['Component'].value_counts().plot(kind='pie', autopct='%1.1f%%', wedgeprops={'alpha':0.75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal bar chart responses by component (lecture/lab etc) \n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['Component'].value_counts().plot(kind='barh')\n",
    "plt.title('Responses by Component')\n",
    "plt.xlabel('Number of responses')\n",
    "plt.ylabel('Component')\n",
    "# show values on bars\n",
    "for index, value in enumerate(df_responses['Component'].value_counts()):\n",
    "    plt.text(value, index, str(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list distinct acad groups\n",
    "print(\"\\nDistinct academic groups:\")\n",
    "print(df_responses['AcadGroup'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal bar chart of responses by acad group\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "fig.set_facecolor('white')\n",
    "df_responses['AcadGroup'].value_counts().plot(kind='barh')\n",
    "plt.title('Responses by Academic Group')\n",
    "plt.xlabel('Number of responses')\n",
    "plt.ylabel('Academic Group')\n",
    "# show values on bars\n",
    "for index, value in enumerate(df_responses['AcadGroup'].value_counts()):\n",
    "    plt.text(value, index, str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree map by acad group\n",
    "plt.figure(figsize=(15, 12))\n",
    "sizes = df_responses['AcadGroup'].value_counts().values\n",
    "labels = df_responses['AcadGroup'].value_counts().index\n",
    "colors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n",
    "sqfy.plot(sizes=sizes, label=labels, color=colors, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list distinct subjects\n",
    "print(\"\\nDistinct subjects:\")\n",
    "print(df_responses['Subject'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use squarify to plot the responses by subject\n",
    "# set the figure size\n",
    "plt.figure(figsize=(50, 40))\n",
    "# plot the treemap\n",
    "sqfy.plot(sizes=df_responses['Subject'].value_counts(), label=df_responses['Subject'].value_counts().index, text_kwargs={'fontsize': 12}, alpha=0.75)\n",
    "plt.axis('off')\n",
    "plt.title('Responses by Subject')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do a tree map by the department + course : \n",
    "# department is subject and course is catalog, so group on two fields\n",
    "# set the figure size\n",
    "plt.figure(figsize=(50, 40))\n",
    "# filter and plot only for math department\n",
    "df_math = df_responses.loc[df_responses['Subject'] == 'MATH']\n",
    "# plot the treemap\n",
    "sqfy.plot(sizes=df_math.groupby(['Subject', 'Catalog']).size(), label=df_math.groupby(['Subject', 'Catalog']).size().index, text_kwargs={'fontsize': 14}, alpha=0.75)\n",
    "plt.axis('off')\n",
    "plt.title('Responses by Department + Course')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do a tree map by the department + course : \n",
    "# department is subject and course is catalog, so group on two fields\n",
    "# set the figure size\n",
    "plt.figure(figsize=(50, 40))\n",
    "# filter and plot only for pharmacy department\n",
    "df_phar = df_responses.loc[df_responses['Subject'] == 'PHAR']\n",
    "# plot the treemap\n",
    "sqfy.plot(sizes=df_phar.groupby(['Subject', 'Catalog']).size(), label=df_phar.groupby(['Subject', 'Catalog']).size().index, text_kwargs={'fontsize': 14}, alpha=0.75)\n",
    "plt.axis('off')\n",
    "plt.title('Responses by Department + Course')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to do a count \n",
    "# also for each acad unit, how many number of subjects\n",
    "# and for each subject, how many number of catalogs\n",
    "# and then for each catalog, how many number of sections\n",
    "\n",
    "# Acad units count: Colleges\n",
    "cnt_acad_units = len(df_responses['AcadGroup'].unique())\n",
    "print(f\"Distinct academic groups: {cnt_acad_units}\")\n",
    "\n",
    "# Subjects count : Departments\n",
    "# list distinct subjects\n",
    "cnt_subjects = len(df_responses['Subject'].unique())\n",
    "print(f\"Distinct subjects: {cnt_subjects}\")\n",
    "\n",
    "# Catalogs count : Courses\n",
    "# list distinct subject+catalogs\n",
    "cnt_catalogs = df_responses.groupby(['Subject', 'Catalog']).size()\n",
    "print(f\"Distinct subject+catalogs: {len(cnt_catalogs)}\")\n",
    "\n",
    "# Sections count\n",
    "# list distinct subject+catalog+ClassNbr\n",
    "cnt_sections = df_responses.groupby(['Subject', 'Catalog', 'ClassNbr']).size()\n",
    "print(f\"Distinct subject+catalog+sections: {len(cnt_sections)}\")\n",
    "\n",
    "# distinct form numbers\n",
    "cnt_forms = len(df_responses['EvaluationForm'].unique())    \n",
    "print(f\"Distinct forms: {cnt_forms}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the distinct forms in the df_responses\n",
    "print(\"\\nDistinct forms:\")\n",
    "forms_in_responses = df_responses['EvaluationForm'].unique()\n",
    "forms_in_responses.sort()\n",
    "for form in forms_in_responses:\n",
    "    print(form)\n",
    "    # check to see if it exists in df_questions\n",
    "    # if so print the questions, otherwise print \"No form found\"\n",
    "    if form in df_questions['FormNumber'].unique():\n",
    "        # print(df_questions.loc[df_questions['FormNumber'] == form]['Question'])\n",
    "        print('Form found')\n",
    "    else:\n",
    "        print(\"No form found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis\n",
    "def sentiment_analysis(text):\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "    # print(f\"text: {text}\")\n",
    "    return sentiment_pipeline(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarizer(model, text):\n",
    "    summarizer = pipeline(\"summarization\", model=model)\n",
    "    cnt_word_tokens = int(len(text.split()))\n",
    "    min_length = int(0.1*cnt_word_tokens)\n",
    "    max_length = int(0.2*cnt_word_tokens)\n",
    "    return summarizer(text, min_length=min_length, max_length=max_length, do_sample = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to iterate through each section\n",
    "# get the form number for each section\n",
    "# look up the questions for each section df_questions\n",
    "# then we can get the responses for each question for each section df_responses\n",
    "# for each response we can do sentiment analysis - use hugging face transformers library\n",
    "# then we count how many are +ve, -ve and neutral\n",
    "# then we concatenate all the comments for the question for each section\n",
    "# and then summarize the comments for each question for each section\n",
    "# then we write it to a file\n",
    "def process_section(instructor, subject, catalog, section_nunber, df_section_responses, df_questions):\n",
    "    print(\"=\"*88)\n",
    "    print(f\"Section: {section_nunber}\")\n",
    "    # print(df_section_responses.head())\n",
    "    # print(\"-\"*50)\n",
    "    print(f\"Number of responses: {len(df_section_responses)}\")\n",
    "    # does it have a form number?\n",
    "    form_numbers = df_section_responses['EvaluationForm'].unique()\n",
    "    if len(form_numbers) == 0:\n",
    "        print(\"No form number found\")\n",
    "        return\n",
    "    elif len(form_numbers) > 1:\n",
    "        print(\"Multiple form numbers found\")\n",
    "        return\n",
    "    else:\n",
    "        form_number = form_numbers[0]\n",
    "        print(f\"Form number: {form_number}\")\n",
    "        # get the questions for the form number\n",
    "        df_form_questions = df_questions.loc[df_questions['FormNumber'] == form_number]\n",
    "        print(f\"Number of questions: {len(df_form_questions)}\")\n",
    "        print(f\"Questions: {df_form_questions}\")\n",
    "\n",
    "        # for each question, get the responses\n",
    "        # comments column is the one we are interested in\n",
    "        # but naming of column is not clear, so we will use the index\n",
    "        comment_starting_index = 12\n",
    "        comment_iter = 0\n",
    "        for index, row in df_form_questions.iterrows():\n",
    "            print(f\"index = {index}\")\n",
    "            question = row['Question']\n",
    "            print(f\"Question: {question}\")\n",
    "            # get the responses for the question\n",
    "            # get the column name\n",
    "            column_name = df_section_responses.columns[comment_starting_index + comment_iter]\n",
    "\n",
    "            # bump comment_iter so for next question, we pick the next column\n",
    "            comment_iter += 1\n",
    "\n",
    "            print(f\"Column name: {column_name}\")\n",
    "            # get the responses\n",
    "            responses = df_section_responses[column_name]\n",
    "            print(f\"Number of responses: {len(responses)}\")\n",
    "\n",
    "            # clean out the responses\n",
    "            # remove nan, empty strings\n",
    "            responses = responses.dropna()\n",
    "            responses = responses[responses != '']\n",
    "\n",
    "            print(f\"Number of responses after cleaning: {len(responses)}\")\n",
    "            # print(f\"Responses: {responses}\")\n",
    "\n",
    "            # sentiment analysis\n",
    "            # convert responses to list of strings\n",
    "            if len(responses) == 0:\n",
    "                print(\"No responses to analyze for sentiments\")\n",
    "            else:\n",
    "                responses = responses.tolist()\n",
    "                sentiments = sentiment_analysis(responses)\n",
    "                # print(sentiments)\n",
    "                \n",
    "            # summarize the comments\n",
    "            SUMMARIZER_LOWER_LIMIT = 200\n",
    "            \n",
    "            # remove newline from within each individual response/comment\n",
    "            responses = [response.replace('\\n', ' ') for response in responses]\n",
    "\n",
    "            # concatenate the comments with a newline\n",
    "            comments = '|'.join(responses)\n",
    "\n",
    "            len_comments = len(comments)\n",
    "            print(f\"Length of comments: {len_comments}\")\n",
    "            if len_comments < SUMMARIZER_LOWER_LIMIT:\n",
    "                print(\"Not enough comments to summarize\")\n",
    "                summary = comments\n",
    "            else:\n",
    "                print(\"=\"*88)\n",
    "                print(f\"len_comments: {len_comments}\")\n",
    "                # print(comments)\n",
    "                model = \"allenai/led-base-16384\"\n",
    "                model = \"google-t5/t5-small\"\n",
    "                summary = summarizer(model, comments)\n",
    "                summary_text = summary[0]['summary_text']\n",
    "                # print(\"-\"*88)\n",
    "                print(f\"len_summary: {len(summary_text)}\")\n",
    "                # print(summary_text)\n",
    "\n",
    "            # write to a file\n",
    "            # create a file in data/out folder\n",
    "            # file name has to be subject_catalog_section_instructor_qNo.txt\n",
    "            # write the question, responses, sentiments, summary\n",
    "            # create folder for model if it doesn't exist\n",
    "            # replace '/' in model with - to avoid creating subfolders\n",
    "            model = model.replace('/', '-')\n",
    "            if not os.path.exists(f\"../data/out/{model}\"):\n",
    "                os.makedirs(f\"../data/out/{model}\")\n",
    "            file_name = f\"../data/out/{model}/{subject}_{catalog}_{section_nunber}_{instructor}_{column_name}.txt\"\n",
    "            with open(file_name, 'w') as file:\n",
    "                file.write(f\"Question: {question}\\n\")\n",
    "                file.write(f\"Responses: {len(responses)}\\n\")\n",
    "                file.write(f\"Comments: {comments}\\n\")\n",
    "                file.write(f\"Sentiments: {sentiments}\\n\")\n",
    "                file.write(f\"Summary: {summary_text}\\n\")\n",
    "            # close the file\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "# we get the list of distinct sections (classNbr)\n",
    "# then for each ClassNbr we filter out its responses \n",
    "distinct_sections = df_responses['ClassNbr'].unique()\n",
    "print(f\"Distinct sections: {len(distinct_sections)}\")\n",
    "\n",
    "processed = False\n",
    "for section_nunber in distinct_sections:\n",
    "    if section_nunber == \"10989A\":\n",
    "        # InstructorName,Subject,Catalog,ClassNbr,Term,SessionCode,distanceed,EvaluationForm,Comment1,Column2,Comment2,Column3,Comment3,Column4,Comment4,Column5,Comment5,Column6,Comment6,Column7,Comment7,Column8,Comment8,Column9,Comment9,Column10,Comment10,Column11,Comment11,,\n",
    "        df_section_responses = df_responses.loc[df_responses['ClassNbr'] == section_nunber]\n",
    "\n",
    "        # get the instructor, subject, catalog\n",
    "        instructor = df_section_responses['InstructorName'].iloc[0]\n",
    "        subject = df_section_responses['Subject'].iloc[0]\n",
    "        catalog = df_section_responses['Catalog'].iloc[0]\n",
    "\n",
    "        print(f\"Now processing section: {section_nunber}\")\n",
    "        process_section(instructor, subject, catalog, section_nunber, df_section_responses, df_questions)\n",
    "        processed = True\n",
    "    \n",
    "    if processed: break\n",
    "    \n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
